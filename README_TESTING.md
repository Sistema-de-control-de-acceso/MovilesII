# Gu√≠a de Testing

## üìã Resumen

Este proyecto implementa tests unitarios y end-to-end (E2E) con cobertura m√≠nima de:
- **Backend Unit Tests**: ‚â•80%
- **Frontend Flutter Unit Tests**: ‚â•75%
- **E2E Tests**: Suite completa para flujos cr√≠ticos
- **Contract Testing**: Validaci√≥n de contratos API

## üõ†Ô∏è Configuraci√≥n

### Backend

```bash
cd backend
npm install
npm test
```

### Frontend Flutter

```bash
flutter pub get
flutter test --coverage
```

## üìä Ejecutar Tests

### Backend

```bash
# Ejecutar todos los tests unitarios con cobertura
npm test

# Ejecutar en modo watch
npm run test:watch

# Ejecutar para CI/CD
npm run test:ci

# Ejecutar tests E2E
npm run test:e2e

# Ejecutar contract tests
npm run test:contracts

# Ejecutar todos los tests (unitarios + E2E + contracts)
npm test && npm run test:e2e && npm run test:contracts
```

### Frontend

```bash
# Ejecutar todos los tests
flutter test

# Ejecutar con cobertura
flutter test --coverage

# Ver reporte de cobertura
genhtml coverage/lcov.info -o coverage/html
open coverage/html/index.html
```

## üìÅ Estructura de Tests

```
backend/
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ setup.js                  # Configuraci√≥n global de tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setup-e2e.js         # Configuraci√≥n para tests E2E
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.e2e.test.js     # Tests E2E de autenticaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users.e2e.test.js    # Tests E2E CRUD usuarios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard.e2e.test.js # Tests E2E de dashboard
‚îÇ   ‚îú‚îÄ‚îÄ contracts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api-contracts.test.js # Contract testing (validaci√≥n de schemas)
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mocks.js              # Mocks reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ validaciones/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validar-movimiento.test.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.test.js
‚îÇ   ‚îú‚îÄ‚îÄ endpoints/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ asistencias.test.js
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ Presencia.test.js

test/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ asistencia_model_test.dart
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ validaciones_test.dart
```

## ‚úÖ Criterios de Aceptaci√≥n

### Cobertura de C√≥digo
- ‚úÖ Backend Unit Tests: ‚â•80% (branches, functions, lines, statements)
- ‚úÖ Frontend Unit Tests: ‚â•75% (l√≠neas de c√≥digo)

### Tests Unitarios
- ‚úÖ Tests para casos edge y manejo de errores
- ‚úÖ Tests para funciones de negocio, validaciones y utilidades

### Tests E2E (End-to-End)
- ‚úÖ Suite de tests E2E que cubra flujos cr√≠ticos:
  - ‚úÖ Autenticaci√≥n (login)
  - ‚úÖ CRUD usuarios (crear, leer, actualizar, eliminar)
  - ‚úÖ Dashboard y m√©tricas
- ‚úÖ Tests ejecut√°ndose contra ambiente de staging
- ‚úÖ Verificaci√≥n de contratos API (request/response esperados)

### Contract Testing
- ‚úÖ Validaci√≥n de schemas JSON con Ajv
- ‚úÖ Verificaci√≥n de tipos de datos y formatos
- ‚úÖ Validaci√≥n de estructura de respuestas API

### Mocks
- ‚úÖ Mocks configurados para MongoDB (mongodb-memory-server)
- ‚úÖ Mocks para servicios externos y dependencias

### CI/CD
- ‚úÖ Tests unitarios ejecut√°ndose autom√°ticamente en GitHub Actions
- ‚úÖ Tests E2E ejecut√°ndose autom√°ticamente
- ‚úÖ Tests contra staging en cada push a main
- ‚úÖ Reporte de cobertura generado y accesible
- ‚úÖ Umbral m√≠nimo que bloquea merges si no se cumple

## üîç Verificar Cobertura

### Backend

Los reportes de cobertura se generan en:
- `backend/coverage/lcov.info` - Formato LCOV
- `backend/coverage/coverage-final.json` - JSON
- `backend/coverage/lcov-report/index.html` - HTML

### Frontend

Los reportes de cobertura se generan en:
- `coverage/lcov.info` - Formato LCOV
- `coverage/html/` - HTML report

## üö® Umbrales de Cobertura

Si la cobertura est√° por debajo del umbral:
- **Backend**: El build fallar√° si < 80%
- **Frontend**: El build fallar√° si < 75%

## üìù Escribir Nuevos Tests

### Backend (Jest)

```javascript
describe('MiFuncion', () => {
  it('debe hacer algo', () => {
    expect(miFuncion()).toBe(expected);
  });
});
```

### Frontend (Flutter Test)

```dart
void main() {
  group('MiClase', () {
    test('debe hacer algo', () {
      expect(miClase.miMetodo(), equals(expected));
    });
  });
}
```

## üîß Troubleshooting

### Backend
- Si los tests fallan con MongoDB, verifica que `mongodb-memory-server` est√© instalado
- Si hay problemas de conexi√≥n, verifica `test/setup.js`
- Para tests E2E, verifica que `test/e2e/setup-e2e.js` est√© configurado correctamente

### Tests E2E
- Aseg√∫rate de que todas las rutas est√©n correctamente cargadas en `setup-e2e.js`
- Verifica que los modelos de MongoDB est√©n correctamente importados
- Si los tests fallan por timeout, aumenta `E2E_TIMEOUT` en la configuraci√≥n

### Contract Testing
- Si falla la validaci√≥n de schemas, verifica que los schemas en `api-contracts.test.js` coincidan con las respuestas reales
- Usa `ajv` con `allErrors: true` para ver todos los errores de validaci√≥n

### Frontend
- Si los tests fallan, ejecuta `flutter clean` y `flutter pub get`
- Verifica que todas las dependencias est√©n en `pubspec.yaml`

## üåê Ambiente de Staging

Los tests E2E se ejecutan contra un ambiente de staging configurado con:

- **Base de datos**: MongoDB separada para staging
- **API**: URL configurada en `STAGING_API_URL`
- **Configuraci√≥n**: Variables de entorno en `backend/config/staging.js`

### Ejecutar Tests contra Staging

**Linux/Mac:**
```bash
# Configurar variables de entorno
export STAGING_API_URL=http://staging-api.example.com
export STAGING_MONGODB_URI=mongodb://staging-db.example.com/asistencia

# Ejecutar script
cd backend
bash scripts/run-e2e-staging.sh
```

**Windows:**
```powershell
# Configurar variables de entorno
$env:STAGING_API_URL = "http://staging-api.example.com"
$env:STAGING_MONGODB_URI = "mongodb://staging-db.example.com/asistencia"

# Ejecutar script
cd backend
.\scripts\run-e2e-staging.ps1
```

**Directo con npm:**
```bash
cd backend
npm run test:e2e:staging
```

### Configurar Variables de Staging

Crear archivo `.env.staging` en `backend/`:

```env
NODE_ENV=staging
MONGODB_URI=mongodb+srv://user:pass@staging-cluster.mongodb.net/ASISTENCIA_STAGING
PORT=3001
API_URL=http://staging-api.example.com
```

## üìã Flujos E2E Cubiertos

### 1. Autenticaci√≥n
- Login exitoso
- Validaci√≥n de credenciales
- Manejo de usuarios inactivos

### 2. CRUD Usuarios
- Crear usuario
- Listar usuarios
- Obtener usuario por ID
- Actualizar usuario
- Eliminar usuario
- Validaci√≥n de duplicados

### 3. Dashboard y M√©tricas
- M√©tricas generales
- Accesos recientes
- Diferentes periodos de tiempo
- Validaci√≥n de estructura de datos

### 4. Flujo Completo
- Secuencia completa: Login ‚Üí Dashboard ‚Üí Gesti√≥n ‚Üí M√©tricas
- Manejo de errores en flujos

## üîç Contract Testing

Los contract tests validan que las respuestas de la API cumplan con los schemas esperados:

- **Schemas JSON**: Definidos con JSON Schema
- **Validaci√≥n**: Usando Ajv (Another JSON Schema Validator)
- **Formatos**: Validaci√≥n de emails, fechas ISO 8601, etc.

### Ejecutar Contract Tests

```bash
cd backend
npm run test:contracts
```

### Agregar Nuevo Schema

Editar `backend/test/contracts/api-contracts.test.js` y agregar el schema:

```javascript
const schemas = {
  nuevoEndpoint: {
    type: 'object',
    required: ['campo1', 'campo2'],
    properties: {
      campo1: { type: 'string' },
      campo2: { type: 'number' },
    },
  },
};
```

## üìä Logging Centralizado

El sistema implementa logging estructurado en formato JSON para facilitar debugging y correlaci√≥n entre mobile y backend.

### Caracter√≠sticas

- **Logs estructurados (JSON)**: Formato est√°ndar para ELK/Datadog/Cloud Logging
- **Request-ID propagation**: Correlaci√≥n entre mobile y backend
- **Eventos cr√≠ticos instrumentados**: Login, asistencias, errores, etc.
- **Retenci√≥n configurada**: Logs disponibles en staging

### Estructura de Logs

Los logs incluyen los siguientes campos:

```json
{
  "timestamp": "2024-01-15 10:30:45.123",
  "level": "info",
  "message": "Login exitoso",
  "service": "moviles2-backend",
  "environment": "staging",
  "requestId": "550e8400-e29b-41d4-a716-446655440000",
  "userId": "user123",
  "endpoint": "/login",
  "method": "POST",
  "statusCode": 200,
  "duration": 150,
  "metadata": {
    "email": "user@example.com",
    "clientType": "mobile"
  }
}
```

### Request-ID

El sistema propaga autom√°ticamente el `request-id` entre mobile y backend:

- **Mobile**: Genera un `request-id` √∫nico y lo env√≠a en el header `X-Request-ID`
- **Backend**: Usa el `request-id` recibido o genera uno nuevo, lo retorna en el header `X-Request-ID`
- **Correlaci√≥n**: Permite rastrear un request completo desde mobile hasta backend

### Acceso a Logs

#### En Desarrollo

Los logs se muestran en consola con formato legible:

```bash
cd backend
npm start
```

#### En Staging

Los logs est√°n disponibles en:

1. **Archivo de logs** (si est√° configurado):
   ```bash
   tail -f logs/app.log
   ```

2. **Sistema de logging centralizado**:
   - Configurar `LOG_ENDPOINT` en variables de entorno
   - Los logs se env√≠an autom√°ticamente al endpoint configurado

### Queries √ötiles

#### Buscar logs por request-id

```bash
# En archivo de logs
grep "550e8400-e29b-41d4-a716-446655440000" logs/app.log

# En sistema centralizado (ejemplo para ELK)
GET /logs/_search
{
  "query": {
    "match": {
      "requestId": "550e8400-e29b-41d4-a716-446655440000"
    }
  }
}
```

#### Buscar logs de un usuario

```bash
# En archivo de logs
grep "\"userId\":\"user123\"" logs/app.log

# En sistema centralizado
GET /logs/_search
{
  "query": {
    "match": {
      "userId": "user123"
    }
  }
}
```

#### Buscar errores en las √∫ltimas horas

```bash
# En archivo de logs
grep "\"level\":\"error\"" logs/app.log | tail -100

# En sistema centralizado
GET /logs/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "level": "error" } },
        { "range": { "timestamp": { "gte": "now-1h" } } }
      ]
    }
  }
}
```

#### Buscar logs de eventos cr√≠ticos

```bash
# Login exitoso
grep "\"message\":\"Login exitoso\"" logs/app.log

# Registro de asistencia
grep "\"message\":\"Asistencia registrada exitosamente\"" logs/app.log

# Errores de autenticaci√≥n
grep "\"message\":\"Login fallido\"" logs/app.log
```

### Tests E2E de Logging

Los tests E2E validan que los logs se generen correctamente:

```bash
cd backend
npm run test:e2e -- logging.e2e.test.js
```

Los tests verifican:
- ‚úÖ Generaci√≥n y propagaci√≥n de request-id
- ‚úÖ Logs en eventos cr√≠ticos (login, asistencias)
- ‚úÖ Formato JSON estructurado
- ‚úÖ Correlaci√≥n mobile-backend

### Configuraci√≥n

#### Variables de Entorno

```env
# Nivel de log (error, warn, info, http, debug)
LOG_LEVEL=info

# Ruta del archivo de logs (opcional)
LOG_FILE_PATH=logs/app.log

# Endpoint para logging centralizado (opcional)
LOG_ENDPOINT=https://logs.example.com/api/logs
```

#### Configuraci√≥n en Staging

Editar `backend/config/staging.js`:

```javascript
module.exports = {
  LOG_LEVEL: process.env.LOG_LEVEL || 'debug',
  LOG_FILE_PATH: process.env.LOG_FILE_PATH || 'logs/staging.log',
  // ... otras configuraciones
};
```

### Instrumentaci√≥n de Eventos Cr√≠ticos

Los siguientes eventos generan logs autom√°ticamente:

#### Backend

- ‚úÖ Login (exitoso y fallido)
- ‚úÖ Registro de asistencias
- ‚úÖ Errores HTTP
- ‚úÖ Requests HTTP (m√©todo, endpoint, duraci√≥n, status)

#### Mobile (Flutter)

- ‚úÖ Inicio de aplicaci√≥n
- ‚úÖ Login (exitoso y fallido)
- ‚úÖ Logout
- ‚úÖ Requests HTTP (request y response)
- ‚úÖ Errores de conexi√≥n
- ‚úÖ Eventos cr√≠ticos (NFC, sincronizaci√≥n)

### Retenci√≥n de Logs

- **Desarrollo**: Logs en consola, sin retenci√≥n
- **Staging**: Logs en archivo (si est√° configurado) y sistema centralizado
- **Producci√≥n**: Logs solo en sistema centralizado

### Troubleshooting

#### Los logs no aparecen

1. Verificar nivel de log configurado:
   ```bash
   echo $LOG_LEVEL
   ```

2. Verificar que el logger est√© inicializado:
   - Backend: Verificar que `requestIdMiddleware` est√© configurado
   - Mobile: Verificar que `LoggingService().initialize()` se llame en `main()`

#### Request-ID no se propaga

1. Verificar headers en requests:
   ```bash
   curl -H "X-Request-ID: test-123" http://localhost:3000/api/info
   ```

2. Verificar que el middleware est√© configurado antes de las rutas

#### Logs no se env√≠an a sistema centralizado

1. Verificar configuraci√≥n de `LOG_ENDPOINT`
2. Verificar conectividad al endpoint
3. Revisar logs de error (los errores de env√≠o son silenciosos para evitar loops)

## üõ°Ô∏è Rate Limiting

El sistema implementa rate limiting para proteger endpoints cr√≠ticos contra abuso y garantizar estabilidad.

### Caracter√≠sticas

- **Rate limiting por endpoint**: Configuraciones espec√≠ficas seg√∫n el tipo de endpoint
- **Respuestas HTTP 429**: Con headers explicativos (Retry-After, X-RateLimit-*)
- **Configuraci√≥n por entorno**: Diferentes l√≠mites para desarrollo, staging y producci√≥n
- **Tests E2E y unitarios**: Validaci√≥n del comportamiento bajo l√≠mite

### Endpoints Protegidos

#### Login
- **L√≠mite**: 5 intentos en producci√≥n, 10 en otros ambientes
- **Ventana**: 15 minutos
- **Tracking**: Por IP + email para mayor precisi√≥n

#### Autenticaci√≥n (cambio de contrase√±a)
- **L√≠mite**: 20 requests en producci√≥n, 50 en otros ambientes
- **Ventana**: 15 minutos

#### CRUD Usuarios
- **L√≠mite**: 30 requests en producci√≥n, 100 en otros ambientes
- **Ventana**: 15 minutos
- **Endpoints**: GET, POST, PUT, DELETE /usuarios

#### Dashboard/M√©tricas
- **L√≠mite**: 30 requests por minuto en producci√≥n, 100 en otros ambientes
- **Ventana**: 1 minuto (m√°s corta por ser computacionalmente costoso)
- **Endpoints**: GET /dashboard/metrics, GET /dashboard/recent-access

#### Asistencias
- **L√≠mite**: 60 requests por minuto en producci√≥n, 200 en otros ambientes
- **Ventana**: 1 minuto
- **Endpoints**: POST /asistencias/completa, POST /asistencias/validar-movimiento

### Respuesta HTTP 429

Cuando se excede el l√≠mite, el servidor retorna:

**Status Code**: `429 Too Many Requests`

**Headers**:
```
Retry-After: 900
X-RateLimit-Limit: 5
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 2024-01-15T10:45:00.000Z
```

**Body**:
```json
{
  "error": "Demasiadas solicitudes",
  "message": "Has excedido el l√≠mite de solicitudes permitidas. Por favor, intenta nuevamente m√°s tarde.",
  "retryAfter": 900,
  "resetTime": "2024-01-15T10:45:00.000Z",
  "limit": 5,
  "windowMs": 900000
}
```

### Configuraci√≥n

#### Variables de Entorno

```env
# Deshabilitar rate limiting en desarrollo (opcional)
SKIP_RATE_LIMIT=true

# NODE_ENV determina la configuraci√≥n autom√°ticamente
NODE_ENV=staging
```

#### Configuraci√≥n en Staging

Editar `backend/config/staging.js`:

```javascript
module.exports = {
  RATE_LIMIT: {
    windowMs: 15 * 60 * 1000, // 15 minutos
    max: 100,
    standardHeaders: true,
    legacyHeaders: false
  },
  // ... otras configuraciones
};
```

### Tests

#### Tests Unitarios

```bash
cd backend
npm test -- rateLimiter.test.js
```

#### Tests E2E

```bash
cd backend
npm run test:e2e -- rateLimiting.e2e.test.js
```

Los tests verifican:
- ‚úÖ Aplicaci√≥n de rate limiting en endpoints cr√≠ticos
- ‚úÖ Respuesta HTTP 429 cuando se excede el l√≠mite
- ‚úÖ Presencia de headers Retry-After y X-RateLimit-*
- ‚úÖ Mensajes de error descriptivos

### Comportamiento en Diferentes Ambientes

#### Desarrollo
- **General**: 1000 requests por 15 minutos (muy permisivo)
- **Login**: 10 intentos por 15 minutos
- **Puede deshabilitarse**: `SKIP_RATE_LIMIT=true`

#### Staging
- **General**: 100 requests por 15 minutos
- **Login**: 10 intentos por 15 minutos
- **Configurable**: En `backend/config/staging.js`

#### Producci√≥n
- **General**: 50 requests por 15 minutos (m√°s restrictivo)
- **Login**: 5 intentos por 15 minutos (muy restrictivo)
- **Siempre activo**: No se puede deshabilitar

### Troubleshooting

#### Rate limiting muy restrictivo

1. Verificar entorno:
   ```bash
   echo $NODE_ENV
   ```

2. Ajustar configuraci√≥n en `backend/config/staging.js` si es staging

3. En desarrollo, usar `SKIP_RATE_LIMIT=true` para deshabilitar

#### No se aplica rate limiting

1. Verificar que `express-rate-limit` est√© instalado:
   ```bash
   npm list express-rate-limit
   ```

2. Verificar que los middlewares est√©n configurados en `index.js`

3. Verificar que no est√© deshabilitado en desarrollo con `SKIP_RATE_LIMIT`

#### Headers no aparecen

1. Verificar que `standardHeaders: true` est√© configurado
2. Los headers solo aparecen cuando se est√° cerca del l√≠mite o se excede
3. Verificar en respuesta 429 que los headers est√©n presentes

### Mejores Pr√°cticas

1. **Implementar retry con backoff exponencial** en el cliente cuando recibe 429
2. **Respetar el header Retry-After** para saber cu√°ndo reintentar
3. **Monitorear logs** para detectar patrones de abuso
4. **Ajustar l√≠mites** seg√∫n patrones de uso reales
5. **Usar rate limiting por IP** para endpoints p√∫blicos
6. **Usar rate limiting por usuario** para endpoints autenticados (futuro)

## üè• Monitoreo de Salud del Sistema

El sistema implementa monitoreo completo de salud en tiempo real para detectar problemas antes de que afecten a usuarios.

### Caracter√≠sticas

- **Dashboard de m√©tricas**: CPU, memoria, disco, base de datos
- **Alertas autom√°ticas**: Configurables con umbrales personalizables
- **Historial de incidentes**: Registro completo de problemas detectados
- **M√©tricas de performance**: API, queries, conexiones

### Endpoints Disponibles

#### GET /health/detailed
Obtiene m√©tricas detalladas del sistema.

**Respuesta**:
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:45.123Z",
  "system": {
    "status": "healthy",
    "metrics": {
      "cpu": {
        "process": { "usage": 15.5, "user": 2.3, "system": 1.2 },
        "system": { "loadPercent": 25.0, "cores": 4, "loadAverage": {...} }
      },
      "memory": {
        "system": { "totalMB": 8192, "usedMB": 4096, "usagePercent": 50.0 },
        "process": { "heapUsed": 128, "heapTotal": 256, "heapUsagePercent": 50.0 }
      },
      "disk": { "platform": "linux", "uptime": {...} },
      "process": { "uptime": {...}, "pid": 12345, "version": "v18.0.0" }
    },
    "issues": []
  },
  "database": {
    "status": "healthy",
    "metrics": {
      "connection": { "isConnected": true, "stateName": "connected" },
      "stats": { "connections": {...}, "operations": {...} },
      "collections": { "totalCollections": 10, "collections": [...] },
      "slowQueries": { "queries": [], "total": 0, "stats": {...} }
    },
    "issues": []
  },
  "issues": [],
  "summary": {
    "totalIssues": 0,
    "criticalIssues": 0,
    "warnings": 0
  }
}
```

#### GET /health/incidents
Obtiene historial de incidentes.

**Par√°metros**:
- `limit`: N√∫mero m√°ximo de incidentes (default: 50)
- `status`: Filtrar por estado (healthy, degraded, unhealthy)
- `resolved`: Filtrar por resuelto (true/false)
- `since`: Filtrar desde fecha (ISO format)

**Ejemplo**:
```bash
GET /health/incidents?limit=20&status=degraded&resolved=false
```

#### GET /health/incidents/stats
Obtiene estad√≠sticas de incidentes.

**Par√°metros**:
- `hours`: Per√≠odo en horas (default: 24)

**Respuesta**:
```json
{
  "period": "24 hours",
  "since": "2024-01-14T10:30:45.123Z",
  "stats": {
    "total": 5,
    "byStatus": { "healthy": 0, "degraded": 3, "unhealthy": 2 },
    "bySeverity": { "critical": 2, "warning": 3 },
    "resolved": 4,
    "unresolved": 1
  }
}
```

#### POST /health/incidents/:id/resolve
Marca un incidente como resuelto.

#### GET /health/thresholds
Obtiene umbrales de alerta actuales.

#### POST /health/thresholds
Configura umbrales de alerta.

**Body**:
```json
{
  "cpu": { "warning": 80, "critical": 95 },
  "memory": { "warning": 80, "critical": 95 },
  "heap": { "warning": 80, "critical": 95 },
  "dbConnections": { "warning": 50, "critical": 100 },
  "slowQueries": { "warning": 5, "critical": 20 }
}
```

#### GET /health/summary
Obtiene resumen completo de salud (incluye m√©tricas, incidentes, alertas).

#### GET /health/alerts
Obtiene historial de alertas enviadas.

**Par√°metros**:
- `limit`: N√∫mero m√°ximo de alertas (default: 50)
- `type`: Filtrar por tipo (cpu, memory, database, etc.)
- `severity`: Filtrar por severidad (warning, critical)
- `since`: Filtrar desde fecha (ISO format)

### Dashboard de Salud

Acceso al dashboard web:
```
http://localhost:3000/dashboard/health.html
```

**Caracter√≠sticas**:
- M√©tricas en tiempo real
- Auto-actualizaci√≥n cada 30 segundos
- Gr√°ficos de progreso visuales
- Lista de problemas detectados
- Historial de incidentes

### Umbrales de Alerta por Defecto

```javascript
{
  cpu: { warning: 80%, critical: 95% },
  memory: { warning: 80%, critical: 95% },
  heap: { warning: 80%, critical: 95% },
  dbConnections: { warning: 50, critical: 100 },
  slowQueries: { warning: 5, critical: 20 }
}
```

### M√©tricas Disponibles

#### Sistema
- **CPU**: Uso del proceso, carga del sistema, n√∫cleos
- **Memoria**: Sistema (total, usado, libre), Proceso (heap, RSS)
- **Disco**: Plataforma, arquitectura, uptime
- **Proceso**: PID, versi√≥n Node.js, uptime

#### Base de Datos
- **Conexi√≥n**: Estado, host, puerto, nombre BD
- **Estad√≠sticas**: Conexiones activas, operaciones, red
- **Colecciones**: Conteo, tama√±o, √≠ndices
- **Queries Lentas**: Historial, estad√≠sticas

### Alertas Autom√°ticas

El sistema env√≠a alertas autom√°ticamente cuando:
- CPU excede umbrales configurados
- Memoria excede umbrales configurados
- Base de datos se desconecta
- Se detectan queries lentas en exceso

**Canales de alerta**:
- **Log**: Siempre activo (registra en sistema de logging)
- **Email**: Configurable (requiere configuraci√≥n adicional)

### Tests

#### Tests Unitarios

```bash
cd backend
npm test -- health_monitoring.test.js
```

#### Tests E2E

```bash
cd backend
npm run test:e2e -- health_monitoring.e2e.test.js
```

Los tests verifican:
- ‚úÖ Obtenci√≥n de m√©tricas del sistema
- ‚úÖ Obtenci√≥n de m√©tricas de BD
- ‚úÖ Detecci√≥n de problemas
- ‚úÖ Registro de incidentes
- ‚úÖ Env√≠o de alertas
- ‚úÖ Historial de incidentes
- ‚úÖ Configuraci√≥n de umbrales

### Configuraci√≥n

#### Variables de Entorno

```env
# No requiere configuraci√≥n adicional
# Los umbrales se configuran v√≠a API o c√≥digo
```

#### Configuraci√≥n Program√°tica

```javascript
const healthMonitoring = require('./services/health_monitoring_service');

// Configurar umbrales
healthMonitoring.setAlertThresholds({
  cpu: { warning: 70, critical: 90 },
  memory: { warning: 75, critical: 90 }
});

// Registrar canal de alerta personalizado
const { EmailAlertChannel } = require('./services/alert_service');
healthMonitoring.alertService.registerChannel(
  new EmailAlertChannel({ to: 'admin@example.com' })
);
```

### Queries √ötiles

#### Verificar salud del sistema

```bash
curl http://localhost:3000/health/detailed
```

#### Obtener incidentes cr√≠ticos

```bash
curl "http://localhost:3000/health/incidents?status=unhealthy&limit=10"
```

#### Obtener estad√≠sticas de √∫ltimas 48 horas

```bash
curl "http://localhost:3000/health/incidents/stats?hours=48"
```

#### Configurar umbrales

```bash
curl -X POST http://localhost:3000/health/thresholds \
  -H "Content-Type: application/json" \
  -d '{
    "cpu": { "warning": 70, "critical": 90 },
    "memory": { "warning": 75, "critical": 90 }
  }'
```

### Troubleshooting

#### Las m√©tricas no aparecen

1. Verificar que los servicios est√©n inicializados:
   ```javascript
   // En index.js debe estar:
   const HealthMonitoringService = require('./services/health_monitoring_service');
   const healthMonitoring = new HealthMonitoringService();
   ```

2. Verificar que los endpoints est√©n registrados

#### Las alertas no se env√≠an

1. Verificar que los canales est√©n registrados
2. Verificar umbrales configurados
3. Revisar logs para errores de env√≠o

#### Dashboard no carga

1. Verificar que el archivo existe: `backend/public/dashboard/health.html`
2. Verificar que el servidor est√© sirviendo archivos est√°ticos
3. Revisar consola del navegador para errores

### Mejores Pr√°cticas

1. **Monitorear regularmente**: Revisar dashboard diariamente
2. **Configurar alertas**: Establecer umbrales apropiados seg√∫n carga esperada
3. **Revisar incidentes**: Resolver incidentes cr√≠ticos inmediatamente
4. **Ajustar umbrales**: Basarse en m√©tricas hist√≥ricas reales
5. **Integrar con sistemas externos**: Conectar con sistemas de monitoreo (Datadog, New Relic, etc.)
6. **Automatizar respuestas**: Configurar acciones autom√°ticas para incidentes cr√≠ticos

## üöÄ Pruebas de Carga y An√°lisis de Performance

Sistema completo de pruebas de carga para garantizar que el sistema soporte la carga esperada y mantenga tiempos de respuesta √≥ptimos.

### Caracter√≠sticas

- ‚úÖ Tests de carga para escenarios de uso pico (horario de entrada/salida)
- ‚úÖ Simulaci√≥n de carga concurrente (m√≠nimo 500 usuarios simult√°neos)
- ‚úÖ Tiempo de respuesta promedio < 200ms para operaciones cr√≠ticas
- ‚úÖ Tasa de √©xito > 99.5% bajo carga normal
- ‚úÖ Identificaci√≥n de cuellos de botella
- ‚úÖ Reporte de m√©tricas de performance (latencia P50, P95, P99)
- ‚úÖ Tests de stress para identificar punto de quiebre
- ‚úÖ Pruebas de resistencia (soak tests) de 24 horas
- ‚úÖ Plan de optimizaci√≥n basado en resultados

### Instalaci√≥n

#### K6 (Herramienta de Testing)

**macOS:**
```bash
brew install k6
```

**Windows:**
```bash
choco install k6
```

**Linux:**
```bash
sudo gpg -k
sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6
```

**Descarga directa:** https://k6.io/docs/getting-started/installation/

### Estructura

```
backend/load-testing/
‚îú‚îÄ‚îÄ k6.config.js              # Configuraci√≥n base
‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îú‚îÄ‚îÄ peak-hours.js         # Horario pico entrada/salida
‚îÇ   ‚îú‚îÄ‚îÄ concurrent-users.js    # 500 usuarios simult√°neos
‚îÇ   ‚îú‚îÄ‚îÄ stress-test.js        # Test de stress (punto de quiebre)
‚îÇ   ‚îî‚îÄ‚îÄ soak-test.js          # Prueba de resistencia 24h
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ run-load-test.sh      # Script bash
‚îÇ   ‚îú‚îÄ‚îÄ run-load-test.ps1     # Script PowerShell
‚îÇ   ‚îú‚îÄ‚îÄ analyze-results.js    # An√°lisis de resultados
‚îÇ   ‚îî‚îÄ‚îÄ setup-staging-data.js # Configurar datos de prueba
‚îî‚îÄ‚îÄ README.md                  # Documentaci√≥n completa
```

### Uso R√°pido

#### 1. Configurar Datos de Prueba

```bash
cd backend/load-testing
node scripts/setup-staging-data.js
```

#### 2. Ejecutar Prueba de Carga

**Linux/macOS:**
```bash
./scripts/run-load-test.sh peak-hours http://localhost:3000
```

**Windows:**
```powershell
.\scripts\run-load-test.ps1 peak-hours http://localhost:3000
```

**Directo:**
```bash
k6 run --env BASE_URL=http://localhost:3000 scenarios/peak-hours.js
```

#### 3. Analizar Resultados

```bash
node scripts/analyze-results.js results/peak-hours-20240115-120000.json
```

### Escenarios Disponibles

#### Peak Hours (Horario Pico)
```bash
k6 run scenarios/peak-hours.js
```
- Simula 200 usuarios durante horario pico
- Login ‚Üí Consulta alumno ‚Üí Registro asistencia
- Duraci√≥n: ~12 minutos

#### Concurrent Users (Usuarios Concurrentes)
```bash
k6 run scenarios/concurrent-users.js
```
- Simula 500 usuarios simult√°neos
- Operaciones variadas
- Duraci√≥n: ~24 minutos

#### Stress Test
```bash
k6 run scenarios/stress-test.js
```
- Incremento gradual hasta 1000 usuarios
- Identifica punto de quiebre
- Duraci√≥n: ~20 minutos

#### Soak Test (24 horas)
```bash
k6 run --duration 24h scenarios/soak-test.js
```
- 50 usuarios constantes
- Detecta memory leaks
- Duraci√≥n: 24 horas

### M√©tricas y Thresholds

#### Thresholds Configurados

```javascript
{
  // Tiempo de respuesta promedio < 200ms
  http_req_duration: ['p(50)<200', 'p(95)<500', 'p(99)<1000'],
  
  // Tasa de √©xito > 99.5%
  http_req_failed: ['rate<0.005'],
  
  // Checks deben pasar
  checks: ['rate>0.995']
}
```

#### M√©tricas Reportadas

- **Response Time**: Min, Max, Promedio, P50, P95, P99
- **Success Rate**: Total requests, Failed requests, Tasa de √©xito
- **Throughput**: Requests por segundo
- **Checks**: Checks pasados/fallidos, Tasa de checks

### Interpretaci√≥n de Resultados

#### ‚úÖ Prueba Exitosa

- P50 < 200ms
- P95 < 500ms
- P99 < 1000ms
- Success rate > 99.5%
- Checks rate > 99.5%

#### ‚ö†Ô∏è Problemas Detectados

**Tiempo de respuesta alto:**
- Revisar queries de BD
- Implementar caching
- Optimizar √≠ndices

**Tasa de √©xito baja:**
- Revisar logs de errores
- Verificar capacidad de BD
- Revisar rate limiting

**P95 alto:**
- Identificar endpoints lentos
- Optimizar operaciones costosas
- Revisar conexiones de BD

### Integraci√≥n con Monitoreo

Durante las pruebas, monitorear el sistema:

```bash
# En otra terminal
curl http://localhost:3000/health/detailed
```

O acceder al dashboard:
```
http://localhost:3000/dashboard/health.html
```

### Reportes

El script de an√°lisis genera:

1. **Reporte en consola**: M√©tricas clave y recomendaciones
2. **Archivo JSON**: An√°lisis completo para procesamiento
3. **Recomendaciones**: Plan de optimizaci√≥n basado en resultados

### Troubleshooting

#### K6 no est√° instalado
```bash
k6 version
# Si no est√°, seguir instrucciones de instalaci√≥n
```

#### Error de conexi√≥n
```bash
curl http://localhost:3000/health
```

#### Resultados no se generan
```bash
mkdir -p results
chmod 755 results
```

### Documentaci√≥n Completa

Ver `backend/load-testing/README.md` para documentaci√≥n detallada.

### Integraci√≥n CI/CD

Las pruebas de carga est√°n integradas en CI/CD. Ver `backend/load-testing/CI_CD_INTEGRATION.md` para detalles completos.

**Sistemas soportados:**
- ‚úÖ GitHub Actions (`.github/workflows/load-testing.yml`)
- ‚úÖ GitLab CI (`.gitlab-ci.yml`)
- ‚úÖ Jenkins (`Jenkinsfile`)
- ‚úÖ Scripts gen√©ricos (`scripts/ci-run.sh`, `scripts/ci-run.ps1`)

**Ejecuci√≥n autom√°tica:**
- Push a main/master/develop
- Pull requests
- Manualmente desde UI

**Resultados:**
- Artifacts guardados por 30 d√≠as
- Comentarios autom√°ticos en PRs (GitHub)
- Reportes JSON y CSV

### Pr√≥ximos Pasos

1. ‚úÖ **Automatizar en CI/CD**: Integrado (ver `CI_CD_INTEGRATION.md`)
2. ‚úÖ **Alertas autom√°ticas**: Integrado para app mobile (ver `docs/MOBILE_MONITORING.md`)
3. **Dashboards**: Visualizaci√≥n en tiempo real
4. **Comparaci√≥n hist√≥rica**: Comparar resultados entre ejecuciones
5. **Optimizaci√≥n continua**: Implementar mejoras basadas en resultados

## üì± Monitoreo y Alertas para App Mobile

Sistema completo de monitoreo y alertas para la aplicaci√≥n mobile en staging.

### Caracter√≠sticas

- ‚úÖ M√©tricas clave (crashes, ANR, latencia, error rate) reportadas a sistema de monitoring
- ‚úÖ Alertas m√≠nimas configuradas (aumento de crash rate, error rate > umbral)
- ‚úÖ Pruebas que disparan alertas en staging y validan notificaciones
- ‚úÖ Dashboard b√°sico disponible para el equipo

### Herramientas

- **Sentry**: Crashes, errores, performance, ANR detection
- **Backend Monitoring**: Sistema de alertas integrado
- **Mobile Alert Service**: Servicio espec√≠fico para m√©tricas mobile

### Configuraci√≥n R√°pida

#### Flutter

1. Configurar DSN de Sentry en `lib/config/monitoring_config.dart`
2. O usar variables de entorno:
   ```bash
   flutter run --dart-define=SENTRY_DSN=your_dsn --dart-define=ENVIRONMENT=staging
   ```

#### Backend

Los endpoints est√°n disponibles en `/api/mobile/monitoring/`:
- `POST /crash` - Reportar crash
- `POST /error` - Reportar error
- `POST /latency` - Reportar latencia
- `POST /anr` - Reportar ANR
- `GET /metrics` - Obtener m√©tricas
- `POST /thresholds` - Configurar umbrales

### Dashboard

Acceso: `http://localhost:3000/dashboard/mobile-monitoring.html`

### Umbrales de Alerta

- **Crash Rate**: > 1% de sesiones
- **Error Rate**: > 5% de requests
- **Latency P95**: > 2 segundos
- **ANR**: > 5 por hora

### Pruebas

```bash
# Disparar alertas para pruebas
node backend/scripts/trigger-mobile-alerts.js all
```

### Documentaci√≥n Completa

Ver `docs/MOBILE_MONITORING.md` para documentaci√≥n detallada.

