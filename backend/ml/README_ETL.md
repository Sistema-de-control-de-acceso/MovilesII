# Sistema ETL de Datos Hist√≥ricos para ML - Documentaci√≥n

## üìã Descripci√≥n

Sistema completo ETL (Extract, Transform, Load) para recopilar, limpiar y validar datos hist√≥ricos de entrada/salida para alimentar algoritmos de Machine Learning.

## ‚úÖ Acceptance Criteria Cumplidos

- ‚úÖ **ETL datos hist√≥ricos implementado**: Pipeline completo de extracci√≥n, transformaci√≥n y carga
- ‚úÖ **Estructura para ML definida**: Schema y validaci√≥n de estructura ML est√°ndar
- ‚úÖ **Limpieza datos automatizada**: Algoritmos avanzados de limpieza y preprocesamiento

## üìÅ Archivos Creados

```
backend/ml/
‚îú‚îÄ‚îÄ historical_data_etl.js          ‚úÖ ETL b√°sico de datos hist√≥ricos
‚îú‚îÄ‚îÄ ml_data_structure.js            ‚úÖ Estructura de datos ML
‚îú‚îÄ‚îÄ data_cleaning_service.js        ‚úÖ Servicio de limpieza de datos
‚îú‚îÄ‚îÄ data_quality_validator.js       ‚úÖ Validador de calidad de datos
‚îî‚îÄ‚îÄ ml_etl_service.js              ‚úÖ Servicio ETL integrado para ML
```

## üöÄ Endpoints Disponibles

### 1. Pipeline ETL Completo para ML

```bash
POST /ml/etl/pipeline
Body: {
  "months": 3,
  "cleanData": true,
  "validateData": true,
  "aggregateByHour": true,
  "normalizeStructure": true
}
```

Ejecuta pipeline completo con extracci√≥n, transformaci√≥n, limpieza y validaci√≥n.

### 2. ETL B√°sico

```bash
POST /ml/etl/basic
Body: {
  "months": 3,
  "cleanData": true,
  "validateData": true,
  "aggregateByHour": true
}
```

Ejecuta ETL b√°sico sin normalizaci√≥n de estructura ML.

### 3. Limpiar Datos

```bash
POST /ml/etl/clean
Body: {
  "dataPath": "/path/to/data.json",
  "strategy": "impute"
}
```

Aplica algoritmos de limpieza a datos existentes.

### 4. Validar Calidad

```bash
POST /ml/etl/validate
Body: {
  "dataPath": "/path/to/data.json"
}
```

Valida calidad de datos existentes.

### 5. Obtener Estad√≠sticas

```bash
GET /ml/etl/statistics
GET /ml/etl/statistics?dataPath=/path/to/data.json
```

Obtiene estad√≠sticas del dataset procesado.

### 6. Obtener Estructura ML

```bash
GET /ml/etl/structure
```

Obtiene estructura ML definida.

### 7. Validar Estructura

```bash
POST /ml/etl/validate-structure
Body: {
  "data": [...]
}
```

Valida que datos cumplan con estructura ML.

### 8. Reporte de Calidad

```bash
POST /ml/etl/quality-report
Body: {
  "dataPath": "/path/to/data.json"
  // o
  "data": [...]
}
```

Genera reporte completo de calidad de datos.

## üîÑ Pipeline ETL Completo

### Fases del Pipeline

1. **EXTRACT** - Extracci√≥n de datos hist√≥ricos
   - Consulta MongoDB por rango de fechas
   - Filtrado y selecci√≥n de campos
   - Guardado de datos raw

2. **TRANSFORM** - Transformaci√≥n de datos
   - Agregaci√≥n por hora (opcional)
   - Extracci√≥n de caracter√≠sticas temporales
   - Normalizaci√≥n de formatos

3. **CLEAN** - Limpieza de datos
   - Eliminaci√≥n de duplicados
   - Manejo de valores faltantes
   - Detecci√≥n y manejo de outliers
   - Normalizaci√≥n de formatos

4. **VALIDATE** - Validaci√≥n de calidad
   - Completitud
   - Consistencia
   - Validez
   - Unicidad
   - Actualidad

5. **NORMALIZE** - Normalizaci√≥n a estructura ML
   - Aplicaci√≥n de schema ML
   - Validaci√≥n de estructura
   - Preparaci√≥n para ML

6. **LOAD** - Carga de datos procesados
   - Guardado de datos procesados
   - Generaci√≥n de reportes

## üìä Estructura de Datos ML

### Schema Definido

```json
{
  "features": {
    "temporal": {
      "hora": { "type": "numeric", "range": [0, 23] },
      "dia_semana": { "type": "numeric", "range": [0, 6] },
      "mes": { "type": "numeric", "range": [1, 12] },
      "es_fin_semana": { "type": "binary", "values": [0, 1] },
      "es_feriado": { "type": "binary", "values": [0, 1] }
    },
    "estudiante": {
      "siglas_facultad": { "type": "string" },
      "siglas_escuela": { "type": "string" }
    },
    "acceso": {
      "tipo": { "type": "categorical", "values": ["entrada", "salida"] },
      "puerta": { "type": "string" }
    }
  },
  "target": {
    "target": { "type": "numeric" },
    "is_peak_hour": { "type": "binary", "values": [0, 1] }
  }
}
```

## üßπ Algoritmos de Limpieza

### Estrategias Implementadas

1. **Valores Faltantes**
   - `impute`: Imputaci√≥n con valores por defecto
   - `remove`: Eliminaci√≥n de registros incompletos
   - `forward_fill`: Forward fill con √∫ltimo valor v√°lido

2. **Outliers**
   - `iqr`: M√©todo IQR (Interquartile Range)
   - `zscore`: M√©todo Z-Score (3 desviaciones est√°ndar)

3. **Normalizaci√≥n**
   - `standard`: Normalizaci√≥n est√°ndar (Z-score)
   - `minmax`: Normalizaci√≥n Min-Max

4. **Codificaci√≥n**
   - `hash`: Codificaci√≥n hash de strings
   - `label`: Codificaci√≥n label (0, 1, 2, ...)

## ‚úÖ Validaci√≥n de Calidad

### Criterios de Validaci√≥n

1. **Completitud** (‚â•95%)
   - Campos requeridos presentes
   - Campos opcionales opcionales

2. **Consistencia** (‚â•95%)
   - Formatos consistentes
   - Rangos v√°lidos
   - L√≥gica consistente

3. **Validez** (‚â•95%)
   - Valores dentro de rangos
   - Tipos correctos
   - Fechas v√°lidas

4. **Unicidad** (‚â•95%)
   - Sin duplicados
   - Identificadores √∫nicos

5. **Actualidad** (‚â•80%)
   - Datos recientes
   - No muy antiguos

### Reporte de Calidad

```json
{
  "summary": {
    "isValid": true,
    "overallScore": 0.9234,
    "meetsThresholds": true,
    "totalRecords": 15000
  },
  "checks": {
    "completeness": {
      "isValid": true,
      "score": 0.9821,
      "status": "PASS"
    },
    "consistency": {
      "isValid": true,
      "score": 0.9634,
      "status": "PASS"
    }
  },
  "recommendations": []
}
```

## üìà Ejemplo de Uso

### 1. Ejecutar Pipeline Completo

```bash
POST /ml/etl/pipeline
Body: {
  "months": 3,
  "cleanData": true,
  "validateData": true
}
```

### 2. Validar Dataset Existente

```bash
POST /ml/etl/validate
Body: {
  "dataPath": "/data/etl/processed/processed_2024-01-15.json"
}
```

### 3. Obtener Estad√≠sticas

```bash
GET /ml/etl/statistics
```

Respuesta incluye:
- Total de registros
- Rango de fechas
- Distribuci√≥n por hora
- Distribuci√≥n por d√≠a
- M√©tricas de calidad

## üí° Caracter√≠sticas Avanzadas

1. **Agregaci√≥n por Hora**: Opci√≥n de agregar datos por hora para reducir tama√±o
2. **Validaci√≥n Multi-Criterio**: Validaci√≥n exhaustiva con m√∫ltiples criterios
3. **Limpieza Configurable**: Estrategias configurables para diferentes necesidades
4. **Reportes Detallados**: Reportes completos de calidad y limpieza
5. **Estructura ML Est√°ndar**: Schema definido y validado para ML

## ‚öôÔ∏è Requisitos

- Datos hist√≥ricos disponibles en MongoDB
- M√≠nimo 100 registros para ML
- Datos con campos requeridos: fecha_hora, tipo

## üìå Notas

- El pipeline puede tardar varios minutos con grandes vol√∫menes de datos
- Los datos raw se guardan en `data/etl/raw/`
- Los datos procesados se guardan en `data/etl/processed/`
- La validaci√≥n es autom√°tica pero configurable
- La estructura ML puede personalizarse seg√∫n necesidades

